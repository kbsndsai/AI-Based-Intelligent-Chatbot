{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b89db88f3414e67a0c2a0c93ba4aed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41a81481cf7c4af48d4639fe05d77aac",
              "IPY_MODEL_efe263dd3af340d4b42c3408c3f00a89",
              "IPY_MODEL_6429175f0c004c2eab12a58d71bb44e3"
            ],
            "layout": "IPY_MODEL_c2574161b96247b489d0947750ebdd82"
          }
        },
        "41a81481cf7c4af48d4639fe05d77aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64cae98f8c14f02827310ae032d180c",
            "placeholder": "​",
            "style": "IPY_MODEL_3e813b6c476840a098689bb3b878915f",
            "value": "Map:   0%"
          }
        },
        "efe263dd3af340d4b42c3408c3f00a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4399e1169147fca2fd03226a3f78e2",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3320c82541b3401c8eca7ed721c425f1",
            "value": 27
          }
        },
        "6429175f0c004c2eab12a58d71bb44e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85795feae8cb4851af3974ac41089982",
            "placeholder": "​",
            "style": "IPY_MODEL_361dd6eb5c4243be96edaa7968d979f8",
            "value": " 0/27 [00:00&lt;?, ? examples/s]"
          }
        },
        "c2574161b96247b489d0947750ebdd82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c64cae98f8c14f02827310ae032d180c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e813b6c476840a098689bb3b878915f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4399e1169147fca2fd03226a3f78e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3320c82541b3401c8eca7ed721c425f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85795feae8cb4851af3974ac41089982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361dd6eb5c4243be96edaa7968d979f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eb5a69e8e7d4db2934015385257fef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2bdf52a286a44a8b2efb84e211f3cbf",
              "IPY_MODEL_47504d3f72644850841dce9a2560c099",
              "IPY_MODEL_8f65d34aa1b04cc5841d126913731669"
            ],
            "layout": "IPY_MODEL_026b7bec8325476f8db478a9d8200c05"
          }
        },
        "f2bdf52a286a44a8b2efb84e211f3cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2175753ecfa64e729277009a85cc41a4",
            "placeholder": "​",
            "style": "IPY_MODEL_76f044e491c8494cae91607d464e5eeb",
            "value": "Map:   0%"
          }
        },
        "47504d3f72644850841dce9a2560c099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5e7b77b3f84f039e6e6927175420e9",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49b8220941e840feb9e1173ef21ce8bc",
            "value": 27
          }
        },
        "8f65d34aa1b04cc5841d126913731669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9f833b4c524e5d81a418e9bebc619e",
            "placeholder": "​",
            "style": "IPY_MODEL_518697c6775a413e89fcc16a66759072",
            "value": " 0/27 [00:00&lt;?, ? examples/s]"
          }
        },
        "026b7bec8325476f8db478a9d8200c05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2175753ecfa64e729277009a85cc41a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f044e491c8494cae91607d464e5eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5e7b77b3f84f039e6e6927175420e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b8220941e840feb9e1173ef21ce8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f9f833b4c524e5d81a418e9bebc619e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518697c6775a413e89fcc16a66759072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet consists of two parts. In the first part, it upgrades `pip`, and in the second part, it installs several Python packages with specific versions. Here's a brief description of each part:\n",
        "\n",
        "1. **Upgrading `pip`**:\n",
        "   - `%pip install --upgrade pip`: This command upgrades the `pip` package manager to the latest version available. It ensures that you have the latest version of `pip` installed, which is often recommended to manage Python packages effectively.\n",
        "\n",
        "2. **Package Installation**:\n",
        "   - `%pip install --disable-pip-version-check \\`: This part starts the installation of multiple Python packages with specific versions. The `--disable-pip-version-check` flag suppresses version check warnings during installation.\n",
        "   - `torch==1.13.1`: Installs PyTorch version 1.13.1.\n",
        "   - `torchdata==0.5.1`: Installs the `torchdata` library with version 0.5.1.\n",
        "   - `pandas`: Installs the `pandas` library. The version is not specified, so it installs the latest version available by default.\n",
        "\n",
        "3. **Quiet Mode**:\n",
        "   - `%pip install \\`: The backslash at the end of the line indicates a continuation to the next line. This part continues the installation of additional packages with specific versions, also in quiet mode.\n",
        "   - `transformers==4.27.2`: Installs the Hugging Face Transformers library with version 4.27.2.\n",
        "   - `datasets==2.11.0`: Installs the `datasets` library with version 2.11.0.\n",
        "   - `evaluate==0.4.0`: Installs the `evaluate` library with version 0.4.0.\n",
        "   - `rouge_score==0.1.2`: Installs the `rouge_score` library with version 0.1.2.\n",
        "   - `loralib==0.1.1`: Installs the `loralib` library with version 0.1.1.\n",
        "   - `peft==0.3.0`: Installs the `peft` library with version 0.3.0.\n",
        "\n",
        "This code snippet ensures that you have the specified versions of the mentioned Python packages installed in your environment, which may be necessary for compatibility with other parts of your code or specific project requirements. The use of the `--quiet` flag suppresses output during package installation to keep the installation process silent."
      ],
      "metadata": {
        "id": "N-0mDTXKjDpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install --disable-pip-version-check \\\n",
        "    torch==1.13.1 \\\n",
        "    torchdata==0.5.1 \\\n",
        "    pandas --quiet\n",
        "\n",
        "%pip install \\\n",
        "    transformers==4.27.2 \\\n",
        "    datasets==2.11.0 \\\n",
        "    evaluate==0.4.0 \\\n",
        "    rouge_score==0.1.2 \\\n",
        "    loralib==0.1.1 \\\n",
        "    peft==0.3.0 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xp6Lp3-srRu",
        "outputId": "4afb838b-b912-4f7e-876c-eb1a44eea9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet imports several Python libraries and classes commonly used in natural language processing and machine learning tasks. Here's a brief description of each part of the code:\n",
        "\n",
        "1. `import pandas as pd`: This line imports the `pandas` library and gives it the alias `pd`. `pandas` is a popular data manipulation and analysis library used for handling structured data, such as data in tabular format (e.g., Excel sheets or CSV files).\n",
        "\n",
        "2. `from datasets import Dataset`: This line imports the `Dataset` class from the `datasets` library. The `datasets` library is often used for managing and working with datasets in natural language processing tasks. The `Dataset` class provides functionality for loading and processing datasets.\n",
        "\n",
        "3. `from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer`: This line imports several classes from the Hugging Face Transformers library:\n",
        "   - `AutoModelForSeq2SeqLM`: This class represents a pretrained sequence-to-sequence model, which is commonly used for tasks like text summarization, translation, and question answering.\n",
        "   - `AutoTokenizer`: This class represents a pretrained tokenizer that can convert text into numerical tokens for input to the model.\n",
        "   - `TrainingArguments`: This class is used for specifying training arguments and configurations when fine-tuning a transformer model.\n",
        "   - `Trainer`: This class is used for training machine learning models, including transformer-based models.\n",
        "\n",
        "4. `import torch`: This line imports the PyTorch library, which is a popular deep learning framework often used for building and training neural networks.\n",
        "\n",
        "5. `import time`: This line imports the `time` module, which provides functions for working with time-related operations in Python.\n",
        "\n",
        "6. `from datasets import Dataset`: This line imports the `Dataset` class again, which might be redundant but does not cause any issues. It's possible to have multiple import statements for the same class or module in Python without any problems.\n",
        "\n",
        "This code snippet sets up the necessary libraries and classes for working with datasets and transformer-based models in a natural language processing or machine learning project. It's a common initial step when preparing for tasks like fine-tuning a model for text generation or summarization."
      ],
      "metadata": {
        "id": "mKEQ2oA_jH_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset  # Import the Dataset class\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "VF34Q6KgqhTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet performs several data preprocessing steps to prepare a dataset for fine-tuning a transformer-based model, such as Google's Flan T5, for summarization. Here's a description of each part of the code:\n",
        "\n",
        "1. **`add_instructions` Function**:\n",
        "   - `add_instructions` is a custom function that takes an example from the dataset and adds an instruction to it.\n",
        "   - The instruction is: \"Please summarize the following dialogue.\"\n",
        "   - It prepends this instruction to the 'dialogue' text in the example.\n",
        "   - The modified example is returned.\n",
        "\n",
        "2. **Loading Data from Excel**:\n",
        "   - It loads data from an Excel file specified by the `excel_path` variable ('NIAA RGS _ GIM changes_Edited.xlsx') into a pandas DataFrame (`df`).\n",
        "\n",
        "3. **Data Cleaning**:\n",
        "   - It drops rows where either the 'dialogue' or 'summary ' columns have missing values (NaN).\n",
        "\n",
        "4. **Converting DataFrame to Hugging Face Dataset**:\n",
        "   - The DataFrame `df` is converted into a Hugging Face `Dataset` using `Dataset.from_pandas(df)`. This is a common step to prepare the data for fine-tuning.\n",
        "\n",
        "5. **Adding Instructions to the Dataset**:\n",
        "   - The `add_instructions` function is applied to each example in the dataset using the `map` method. This adds the instruction to each 'dialogue' in the dataset.\n",
        "\n",
        "6. **Tokenizer Initialization**:\n",
        "   - The tokenizer for the model is initialized with the model name 'google/flan-t5-base' using `AutoTokenizer.from_pretrained(model_name)`.\n",
        "\n",
        "7. **Tokenization and Encoding Function**:\n",
        "   - `tokenize_and_encode` is a custom function that tokenizes and encodes the 'dialogue' and 'summary ' text.\n",
        "   - It uses the initialized tokenizer to tokenize the inputs and labels.\n",
        "   - The labels are renamed to 'labels' as expected by Hugging Face's training process.\n",
        "   - Padding tokens are set to -100 in labels to prevent loss computation on padding tokens.\n",
        "\n",
        "8. **Applying Tokenization and Encoding**:\n",
        "   - The `tokenize_and_encode` function is applied to the dataset with instructions using `map`.\n",
        "   - This tokenizes and encodes the examples, and the resulting dataset is ready for training.\n",
        "\n",
        "The code prepares the dataset for fine-tuning a summarization model, ensuring that instructions are added, and the data is tokenized and encoded appropriately for training with the specified model."
      ],
      "metadata": {
        "id": "re6rO_LujNTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to add instructions to the dataset\n",
        "def add_instructions(example):\n",
        "    instruction = \"Please summarize the following dialogue:\"\n",
        "    # Prepend the instruction to the 'dialogue' text\n",
        "    example['dialogue'] = f\"{instruction} {example['dialogue']}\"\n",
        "    return example\n",
        "\n",
        "# Load your dataset from the Excel file\n",
        "excel_path = 'NIAA RGS _ GIM changes_Edited.xlsx'\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# Assuming your DataFrame columns are 'dialogue' and 'summary'\n",
        "# Let's first drop the rows where 'dialogue' or 'summary' column is NaN\n",
        "df = df.dropna(subset=['dialogue', 'summary '])\n",
        "\n",
        "# Convert the DataFrame to a Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Add instructions to each example in the dataset\n",
        "dataset_with_instructions = dataset.map(add_instructions)\n",
        "\n",
        "# The tokenizer you're using\n",
        "model_name = 'google/flan-t5-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_and_encode(examples):\n",
        "    # Tokenize the inputs and labels\n",
        "    tokenized_inputs = tokenizer(examples['dialogue'], padding='max_length', truncation=True, max_length=512)\n",
        "    tokenized_labels = tokenizer(examples['summary '], padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    # Hugging Face expects the labels to be named 'labels', not 'input_ids'\n",
        "    tokenized_labels[\"labels\"] = tokenized_labels[\"input_ids\"]\n",
        "    # We don't need to compute loss for padding tokens\n",
        "    tokenized_labels[\"labels\"] = [\n",
        "        [(label if label != tokenizer.pad_token_id else -100) for label in labels] for labels in tokenized_labels[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    # Return the tokenized inputs and labels\n",
        "    return {\"input_ids\": tokenized_inputs[\"input_ids\"], \"attention_mask\": tokenized_inputs[\"attention_mask\"], \"labels\": tokenized_labels[\"labels\"]}\n",
        "\n",
        "# Apply the tokenization and encoding function to the dataset\n",
        "tokenized_dataset = dataset_with_instructions.map(tokenize_and_encode, batched=True)\n",
        "\n",
        "# Now, tokenized_dataset is ready to be used for training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "6b89db88f3414e67a0c2a0c93ba4aed1",
            "41a81481cf7c4af48d4639fe05d77aac",
            "efe263dd3af340d4b42c3408c3f00a89",
            "6429175f0c004c2eab12a58d71bb44e3",
            "c2574161b96247b489d0947750ebdd82",
            "c64cae98f8c14f02827310ae032d180c",
            "3e813b6c476840a098689bb3b878915f",
            "fc4399e1169147fca2fd03226a3f78e2",
            "3320c82541b3401c8eca7ed721c425f1",
            "85795feae8cb4851af3974ac41089982",
            "361dd6eb5c4243be96edaa7968d979f8",
            "0eb5a69e8e7d4db2934015385257fef0",
            "f2bdf52a286a44a8b2efb84e211f3cbf",
            "47504d3f72644850841dce9a2560c099",
            "8f65d34aa1b04cc5841d126913731669",
            "026b7bec8325476f8db478a9d8200c05",
            "2175753ecfa64e729277009a85cc41a4",
            "76f044e491c8494cae91607d464e5eeb",
            "4a5e7b77b3f84f039e6e6927175420e9",
            "49b8220941e840feb9e1173ef21ce8bc",
            "2f9f833b4c524e5d81a418e9bebc619e",
            "518697c6775a413e89fcc16a66759072"
          ]
        },
        "id": "AcJwDy-Ulds_",
        "outputId": "baabfd22-e6b4-4319-ec93-406ff868c335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/27 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b89db88f3414e67a0c2a0c93ba4aed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/27 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0eb5a69e8e7d4db2934015385257fef0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet checks if a GPU (CUDA device) is available and sets it as the device for PyTorch operations. Here's a brief description of how the code works:\n",
        "\n",
        "1. `torch.cuda.is_available()`: This function checks if a CUDA-enabled GPU is available for use with PyTorch. If a compatible GPU is present, it returns `True`; otherwise, it returns `False`.\n",
        "\n",
        "2. `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`: This line uses a conditional expression to select the device based on the result of `torch.cuda.is_available()`. If a GPU is available, it sets the device to \"cuda\"; otherwise, it sets it to \"cpu\".\n",
        "\n",
        "3. `print(f\"Using device: {device}\")`: This line prints the selected device (either \"cuda\" or \"cpu\") to the console to inform the user about the device that will be used for computation.\n",
        "\n",
        "In summary, this code checks for the availability of a GPU and configures PyTorch to use it if one is available. If no GPU is found, it falls back to using the CPU for computations. It's a common practice to ensure that machine learning models utilize available GPU resources when training or performing inference for faster computation."
      ],
      "metadata": {
        "id": "Y4vy0jwxjTj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available and set it as the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCsGpVwVrVpb",
        "outputId": "b8f21390-1245-4285-f127-7ed826ef6f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet trains a sequence-to-sequence language model using the Hugging Face Transformers library. Here's a description of each part of the code:\n",
        "\n",
        "1. **Loading the Model**:\n",
        "   - The code loads a pretrained sequence-to-sequence model using `AutoModelForSeq2SeqLM.from_pretrained(model_name)`. The `model_name` variable specifies the model to load.\n",
        "\n",
        "2. **Callback for Logging Loss**:\n",
        "   - It defines a custom callback class `PrintLossCallback` that inherits from `TrainerCallback`. This callback will print the training loss at regular intervals during training.\n",
        "\n",
        "3. **Moving the Model to GPU**:\n",
        "   - After loading the model, it moves the model to the GPU (if available) using `model = model.to(device)`. This step is done to utilize GPU resources for training, which can significantly speed up the process.\n",
        "\n",
        "4. **Training Arguments**:\n",
        "   - It sets up the training arguments using `TrainingArguments`. Key training configurations include:\n",
        "     - `output_dir`: Specifies the directory where model checkpoints and results will be saved.\n",
        "     - `num_train_epochs`: Defines the number of training epochs (3 in this case).\n",
        "     - `per_device_train_batch_size`: Specifies the batch size for training (set to 1).\n",
        "     - `warmup_steps`: The number of warm-up steps for learning rate scheduling.\n",
        "     - `weight_decay`: Weight decay applied during optimization.\n",
        "     - `logging_dir` and `logging_steps`: Specify the directory and frequency for logging training information.\n",
        "     - `fp16`: Enables mixed precision training, which can speed up training with reduced memory usage.\n",
        "     - `save_strategy`: Disables model checkpointing (\"no\" strategy) to save memory.\n",
        "\n",
        "5. **Initializing Trainer**:\n",
        "   - The `Trainer` class is initialized with the following arguments:\n",
        "     - `model`: The pretrained model.\n",
        "     - `args`: The training arguments.\n",
        "     - `train_dataset`: The tokenized training dataset (assumed to be defined as `tokenized_dataset`).\n",
        "     - `callbacks`: A list of callbacks, including `PrintLossCallback` for logging loss.\n",
        "\n",
        "6. **Training the Model**:\n",
        "   - Finally, the code initiates the training process using `trainer.train()`. The model will be trained for the specified number of epochs and other training settings defined in the training arguments.\n",
        "\n",
        "This code snippet is an example of how to set up and train a sequence-to-sequence language model using Hugging Face Transformers. It also includes custom callbacks for monitoring training progress, such as printing the loss during training steps."
      ],
      "metadata": {
        "id": "sfzFtdcPjYBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments, TrainerCallback\n",
        "\n",
        "# Load the model using torch.no_grad() to save memory\n",
        "with torch.no_grad():\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Define a callback to print the loss\n",
        "class PrintLossCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if state.is_local_process_zero:\n",
        "            if logs is not None and 'loss' in logs:\n",
        "                print(f\"Step: {state.global_step}, Loss: {logs['loss']}\")\n",
        "\n",
        "\n",
        "# Move the model to GPU after it's loaded to avoid doubling the memory usage\n",
        "model = model.to(device)\n",
        "\n",
        "# Setup training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./model_output',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,  # Further reduce the batch size\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    fp16=True,  # Use mixed precision training\n",
        "    save_strategy=\"no\",  # Disable model checkpointing\n",
        ")\n",
        "\n",
        "# Initialize Trainer with the callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,  # Your tokenized dataset variable\n",
        "    callbacks=[PrintLossCallback]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "Vo5eua0nqtWY",
        "outputId": "7cbacfe1-e2b2-4079-98fb-94586efaf3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [81/81 00:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 10, Loss: 0.0\n",
            "Step: 20, Loss: 0.0\n",
            "Step: 30, Loss: 0.0\n",
            "Step: 40, Loss: 0.0\n",
            "Step: 50, Loss: 0.0\n",
            "Step: 60, Loss: 0.0\n",
            "Step: 70, Loss: 0.0\n",
            "Step: 80, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=81, training_loss=0.0, metrics={'train_runtime': 14.8556, 'train_samples_per_second': 5.452, 'train_steps_per_second': 5.452, 'total_flos': 55465345548288.0, 'train_loss': 0.0, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}